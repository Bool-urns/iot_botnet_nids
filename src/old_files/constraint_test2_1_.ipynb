{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "constraint_test2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onYnaiqnUH-g",
        "colab_type": "text"
      },
      "source": [
        "Testing ProtoNN and Bonsai models with dataset for this project\n",
        "\n",
        "Code taken from: https://github.com/microsoft/EdgeML\n",
        "\n",
        "minor model testing of LSTM model at the very end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApwE7l5EfMwX",
        "colab_type": "text"
      },
      "source": [
        "# Adding Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XtRU-aAe0lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data analysis packages\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk3eJyMGey7X",
        "colab_type": "code",
        "outputId": "75ee28c6-5830-48e0-a847-6fe19b2b8e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Dataset/EdgeML/tf\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYG4ZFhfSX2",
        "colab_type": "text"
      },
      "source": [
        "# Including the relevant library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jai_EnzeXEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/microsoft/EdgeML.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlu9yRbUfYPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#!pip install -r EdgeML/tf/requirements-cpu.txt\n",
        "#!pip install -e EdgeML/tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73nkazj5P9uZ",
        "colab_type": "code",
        "outputId": "3dbbacb8-8f04-46dc-cc97-4f8f274a30e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cd EdgeML/tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'EdgeML/tf'\n",
            "/content/drive/My Drive/Dataset/EdgeML/tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urCq25ctPrjj",
        "colab_type": "code",
        "outputId": "806b5002-e84f-4169-fc64-3f59fc8c5a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbot_iot_dataset\u001b[0m/  \u001b[01;34mexamples\u001b[0m/         requirements-cpu.txt  \u001b[01;34musps10\u001b[0m/\n",
            "\u001b[01;34mdocs\u001b[0m/             helpermethods.py  requirements-gpu.txt\n",
            "\u001b[01;34medgeml\u001b[0m/           \u001b[01;34m__pycache__\u001b[0m/      \u001b[01;34msampled_dataset\u001b[0m/\n",
            "\u001b[01;34medgeml.egg-info\u001b[0m/  README.md         setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBDsXixRfa9-",
        "colab_type": "text"
      },
      "source": [
        "# ProtoNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1TW52HpRsao",
        "colab_type": "text"
      },
      "source": [
        "## Testing parts of old dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIOTHJQzJnO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = './usps10'\n",
        "orig_train, orig_test = np.load(DATA_DIR + '/train.npy'), np.load(DATA_DIR + '/test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6slvYodKEz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(orig_train.shape)\n",
        "print(orig_test.shape)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "print(orig_train)\n",
        "print(train)\n",
        "\n",
        "#np.ptp(train,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYixXacumglv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.load('s_train_combined.npy')\n",
        "\n",
        "test = np.load('s_test_combined.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbAlnbQHRwdy",
        "colab_type": "text"
      },
      "source": [
        "## Opening new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZcsHCijctxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT license.\n",
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
        "from edgeml.graph.protoNN import ProtoNN\n",
        "import edgeml.utils as utils\n",
        "import helpermethods as helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCELyx30T3ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_onehot(y, numClasses, minlabel = None):\n",
        "    '''\n",
        "    If the y labelling does not contain the minimum label info, use min-label to\n",
        "    provide this value.\n",
        "    '''\n",
        "    lab = y.astype('uint8')\n",
        "    if minlabel is None:\n",
        "        minlabel = np.min(lab)\n",
        "    minlabel = int(minlabel)\n",
        "    lab = np.array(lab) - minlabel\n",
        "    lab_ = np.zeros((y.shape[0], numClasses))\n",
        "    lab_[np.arange(y.shape[0]), lab] = 1\n",
        "    return lab_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7YwKlud2T8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "#DATA_DIR = './usps10'\n",
        "DATA_DIR = \"bot_iot_dataset/\" #BotIoT dataset\n",
        "OUT_DIR  = \"bot_iot_dataset/ProtoNN_output\"\n",
        "#DATA_DIR = \"sampled_dataset/\" #N_BaIoT dataset\n",
        "\n",
        "#train, test = np.load(DATA_DIR + '/train.npy'), np.load(DATA_DIR + '/test.npy') #three class version\n",
        "#train, test = np.load(DATA_DIR + '/train_all_classes.npy'), np.load(DATA_DIR + '/test_all_classes.npy')\n",
        "#train, test = np.load(DATA_DIR + '//train_15w_11c.npy'), np.load(DATA_DIR + '//test_15w_11c.npy')\n",
        "train, test = np.load(DATA_DIR + '//bot_iot_train_10.npy'), np.load(DATA_DIR + '//bot_iot_test_10.npy')\n",
        "\n",
        "x_train, y_train = train[:, 1:], train[:, 0]\n",
        "x_test, y_test = test[:, 1:], test[:, 0]\n",
        "\n",
        "numClasses = max(y_train) - min(y_train) + 1\n",
        "numClasses = max(numClasses, max(y_test) - min(y_test) + 1)\n",
        "numClasses = int(numClasses)\n",
        "\n",
        "#y_train = helper.to_onehot(y_train, numClasses)\n",
        "#y_test = helper.to_onehot(y_test, numClasses)\n",
        "\n",
        "y_train = to_onehot(y_train, numClasses)\n",
        "y_test = to_onehot(y_test, numClasses)\n",
        "\n",
        "dataDimension = x_train.shape[1]\n",
        "numClasses = y_train.shape[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJSb0Z2tl3G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessData(train, test):\n",
        "    '''\n",
        "    Loads data from the dataDir and does some initial preprocessing\n",
        "    steps. Data is assumed to be contained in two files,\n",
        "    train.npy and test.npy. Each containing a 2D numpy array of dimension\n",
        "    [numberOfExamples, numberOfFeatures + 1]. The first column of each\n",
        "    matrix is assumed to contain label information.\n",
        "    For an N-Class problem, we assume the labels are integers from 0 through\n",
        "    N-1.\n",
        "    '''\n",
        "    dataDimension = int(train.shape[1]) - 1\n",
        "    x_train = train[:, 1:dataDimension + 1]\n",
        "    y_train_ = train[:, 0]\n",
        "    x_test = test[:, 1:dataDimension + 1]\n",
        "    y_test_ = test[:, 0]\n",
        "\n",
        "    numClasses = max(y_train_) - min(y_train_) + 1\n",
        "    numClasses = max(numClasses, max(y_test_) - min(y_test_) + 1)\n",
        "    numClasses = int(numClasses)\n",
        "\n",
        "    # mean-var\n",
        "    mean = np.mean(x_train, 0)\n",
        "    std = np.std(x_train, 0)\n",
        "    std[std[:] < 0.000001] = 1\n",
        "    x_train = (x_train - mean) / std\n",
        "    x_test = (x_test - mean) / std\n",
        "\n",
        "    # one hot y-train\n",
        "    lab = y_train_.astype('uint8')\n",
        "    lab = np.array(lab) - min(lab)\n",
        "    lab_ = np.zeros((x_train.shape[0], numClasses))\n",
        "    lab_[np.arange(x_train.shape[0]), lab] = 1\n",
        "    y_train = lab_\n",
        "\n",
        "    # one hot y-test\n",
        "    lab = y_test_.astype('uint8')\n",
        "    lab = np.array(lab) - min(lab)\n",
        "    lab_ = np.zeros((x_test.shape[0], numClasses))\n",
        "    lab_[np.arange(x_test.shape[0]), lab] = 1\n",
        "    y_test = lab_\n",
        "\n",
        "    return dataDimension, numClasses, x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v245HUGUL_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getGamma(gammaInit, projectionDim, dataDim, numPrototypes, x_train):\n",
        "    if gammaInit is None:\n",
        "        print(\"Using median heuristic to estimate gamma.\")\n",
        "        gamma, W, B = utils.medianHeuristic(x_train, projectionDim,\n",
        "                                            numPrototypes)\n",
        "        print(\"Gamma estimate is: %f\" % gamma)\n",
        "        return W, B, gamma\n",
        "    return None, None, gammaInit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sDVCUaEYb1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getModelSize(matrixList, sparcityList, expected=True, bytesPerVar=4):\n",
        "    '''\n",
        "    expected: Expected size according to the parameters set. The number of\n",
        "        zeros could actually be more than that is required to satisfy the\n",
        "        sparsity constraint.\n",
        "    '''\n",
        "    nnzList, sizeList, isSparseList = [], [], []\n",
        "    hasSparse = False\n",
        "    for i in range(len(matrixList)):\n",
        "        A, s = matrixList[i], sparcityList[i]\n",
        "        assert A.ndim == 2\n",
        "        assert s >= 0\n",
        "        assert s <= 1\n",
        "        nnz, size, sparse = utils.countnnZ(A, s, bytesPerVar=bytesPerVar)\n",
        "        nnzList.append(nnz)\n",
        "        sizeList.append(size)\n",
        "        hasSparse = (hasSparse or sparse)\n",
        "\n",
        "    totalnnZ = np.sum(nnzList)\n",
        "    totalSize = np.sum(sizeList)\n",
        "    if expected:\n",
        "        return totalnnZ, totalSize, hasSparse\n",
        "    numNonZero = 0\n",
        "    totalSize = 0\n",
        "    hasSparse = False\n",
        "    for i in range(len(matrixList)):\n",
        "        A, s = matrixList[i], sparcityList[i]\n",
        "        numNonZero_ = np.count_nonzero(A)\n",
        "        numNonZero += numNonZero_\n",
        "        hasSparse = (hasSparse or (s < 0.5))\n",
        "        if s <= 0.5:\n",
        "            totalSize += numNonZero_ * 2 * bytesPerVar\n",
        "        else:\n",
        "            totalSize += A.size * bytesPerVar\n",
        "    return numNonZero, totalSize, hasSparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb3tYQBWlP7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, _, x_train, y_train, x_test, y_test = preprocessData(train, test)\n",
        "\n",
        "y_ = np.expand_dims(np.argmax(y_train, axis=1), axis=1)\n",
        "train = np.concatenate([y_, x_train], axis=1)\n",
        "\n",
        "y_ = np.expand_dims(np.argmax(y_test, axis=1), axis=1)\n",
        "test = np.concatenate([y_, x_test], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlMBQxzp2wwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "PROJECTION_DIM = 60\n",
        "NUM_PROTOTYPES = 60\n",
        "REG_W = 0.000005\n",
        "REG_B = 0.0\n",
        "REG_Z = 0.00005\n",
        "SPAR_W = 0.8\n",
        "SPAR_B = 1.0\n",
        "SPAR_Z = 1.0\n",
        "LEARNING_RATE = 0.05\n",
        "#NUM_EPOCHS = 200\n",
        "NUM_EPOCHS = 20\n",
        "#BATCH_SIZE = 32\n",
        "BATCH_SIZE = 100\n",
        "GAMMA = 0.0015\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8frhvygw211r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#W, B, gamma = helper.getGamma(GAMMA, PROJECTION_DIM, dataDimension, NUM_PROTOTYPES, x_train)\n",
        "\n",
        "W, B, gamma = getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
        "                       NUM_PROTOTYPES, x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxmpYq6u27j6",
        "colab_type": "code",
        "outputId": "05e16abf-8517-4cfa-ac24-3ae503fc486b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "# Setup input and train protoNN\n",
        "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
        "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
        "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
        "                  NUM_PROTOTYPES, numClasses,\n",
        "                  gamma, W=W, B=B)\n",
        "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
        "                         SPAR_W, SPAR_B, SPAR_Z,\n",
        "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
        "sess = tf.Session()\n",
        "trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
        "              printStep=600, valStep=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0717 08:54:21.328780 139790765213568 deprecation_wrapper.py:119] From /content/drive/My Drive/Dataset/EdgeML/tf/edgeml/trainer/protoNNTrainer.py:109: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0717 08:54:21.457077 139790765213568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0717 08:54:21.534565 139790765213568 deprecation_wrapper.py:119] From /content/drive/My Drive/Dataset/EdgeML/tf/edgeml/trainer/protoNNTrainer.py:115: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0717 08:54:21.538416 139790765213568 deprecation_wrapper.py:119] From /content/drive/My Drive/Dataset/EdgeML/tf/edgeml/trainer/protoNNTrainer.py:123: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0717 08:54:21.573308 139790765213568 deprecation_wrapper.py:119] From /content/drive/My Drive/Dataset/EdgeML/tf/edgeml/trainer/protoNNTrainer.py:173: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0 Batch:   0 Loss: 4.89323 Accuracy: 0.33000\n",
            "Epoch:   1 Batch:   0 Loss: 0.72883 Accuracy: 0.70000\n",
            "Epoch:   2 Batch:   0 Loss: 0.51062 Accuracy: 0.85000\n",
            "Epoch:   3 Batch:   0 Loss: 0.43267 Accuracy: 0.84000\n",
            "Epoch:   4 Batch:   0 Loss: 0.39050 Accuracy: 0.84000\n",
            "Epoch:   5 Batch:   0 Loss: 0.36783 Accuracy: 0.87000\n",
            "Epoch:   6 Batch:   0 Loss: 0.35228 Accuracy: 0.88000\n",
            "Epoch:   7 Batch:   0 Loss: 0.34193 Accuracy: 0.90000\n",
            "Epoch:   8 Batch:   0 Loss: 0.33493 Accuracy: 0.90000\n",
            "Epoch:   9 Batch:   0 Loss: 0.32985 Accuracy: 0.90000\n",
            "Test Loss: 0.37845 Accuracy: 0.86120\n",
            "Epoch:  10 Batch:   0 Loss: 0.32600 Accuracy: 0.90000\n",
            "Epoch:  11 Batch:   0 Loss: 0.32292 Accuracy: 0.91000\n",
            "Epoch:  12 Batch:   0 Loss: 0.32029 Accuracy: 0.91000\n",
            "Epoch:  13 Batch:   0 Loss: 0.31795 Accuracy: 0.91000\n",
            "Epoch:  14 Batch:   0 Loss: 0.31574 Accuracy: 0.91000\n",
            "Epoch:  15 Batch:   0 Loss: 0.31376 Accuracy: 0.90000\n",
            "Epoch:  16 Batch:   0 Loss: 0.31201 Accuracy: 0.89000\n",
            "Epoch:  17 Batch:   0 Loss: 0.31054 Accuracy: 0.89000\n",
            "Epoch:  18 Batch:   0 Loss: 0.30928 Accuracy: 0.89000\n",
            "Epoch:  19 Batch:   0 Loss: 0.30825 Accuracy: 0.89000\n",
            "Test Loss: 0.35896 Accuracy: 0.86789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dduBIdS3DgX",
        "colab_type": "code",
        "outputId": "6e7169a2-b28c-4a4e-d9a9-11a6cee59ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
        "# W, B, Z are tensorflow graph nodes\n",
        "W, B, Z, _ = protoNN.getModelMatrices()\n",
        "matrixList = sess.run([W, B, Z])\n",
        "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
        "#nnz, size, sparse = helper.getModelSize(matrixList, sparcityList)\n",
        "nnz, size, sparse = getModelSize(matrixList, sparcityList)\n",
        "print(\"Final test accuracy\", acc)\n",
        "print(\"Model size constraint (Bytes): \", size)\n",
        "print(\"Number of non-zeros: \", nnz)\n",
        "#nnz, size, sparse = helper.getModelSize(matrixList, sparcityList, expected=False)\n",
        "nnz, size, sparse = getModelSize(matrixList, sparcityList, expected=False)\n",
        "print(\"Actual model size: \", size)\n",
        "print(\"Actual non-zeros: \", nnz)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final test accuracy 0.8678842\n",
            "Model size constraint (Bytes):  18960\n",
            "Number of non-zeros:  4740\n",
            "Actual model size:  18960\n",
            "Actual non-zeros:  4632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agK1-YXVjiDK",
        "colab_type": "code",
        "outputId": "e979fd59-574d-4d07-8cd6-8addb96d0ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Saving model matrices to: \", OUT_DIR)\n",
        "np.save(OUT_DIR + '/W.npy', matrixList[0])\n",
        "np.save(OUT_DIR + '/B.npy', matrixList[1])\n",
        "np.save(OUT_DIR + '/Z.npy', matrixList[2])\n",
        "np.save(OUT_DIR + '/gamma.npy', gamma)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model matrices to:  bot_iot_dataset/ProtoNN_output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzl2w2TVB7fu",
        "colab_type": "text"
      },
      "source": [
        "# Bonsai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PeQKhsMCFHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cp helpermethods.py ../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsikC_OgB9gG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT license.\n",
        "\n",
        "import helpermethods\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "#Provide the GPU number to be used\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] =''\n",
        "\n",
        "#Bonsai imports\n",
        "from edgeml.trainer.bonsaiTrainer import BonsaiTrainer\n",
        "from edgeml.graph.bonsai import Bonsai\n",
        "\n",
        "# Fixing seeds for reproducibility\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eLy4wljE71K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preProcessData(dataDir, isRegression=False):\n",
        "    '''\n",
        "    Function to pre-process input data\n",
        "    Expects a .npy file of form [lbl feats] for each datapoint\n",
        "    Outputs a train and test set datapoints appended with 1 for Bias induction\n",
        "    dataDimension, numClasses are inferred directly\n",
        "    '''\n",
        "    \n",
        "    '''\n",
        "    #eleven class version\n",
        "    train = np.load(dataDir + '/train_all_classes.npy')\n",
        "    test = np.load(dataDir + '/test_all_classes.npy')\n",
        "    '''\n",
        "    '''\n",
        "    train = np.load(dataDir + '/train_100w_11c.npy')\n",
        "    test = np.load(dataDir + '/test_100w_11c.npy')\n",
        "    '''\n",
        "    '''\n",
        "    train = np.load(dataDir + '/train.npy')\n",
        "    test = np.load(dataDir + '/test.npy')\n",
        "    '''\n",
        "    train = np.load(dataDir + '/bot_iot_train_10.npy')\n",
        "    test = np.load(dataDir + '/bot_iot_test_10.npy')\n",
        "    \n",
        "    dataDimension = int(train.shape[1]) - 1\n",
        "\n",
        "    Xtrain = train[:, 1:dataDimension + 1]\n",
        "    Ytrain_ = train[:, 0]\n",
        "\n",
        "    Xtest = test[:, 1:dataDimension + 1]\n",
        "    Ytest_ = test[:, 0]\n",
        "\n",
        "    # Mean Var Normalisation\n",
        "    mean = np.mean(Xtrain, 0)\n",
        "    std = np.std(Xtrain, 0)\n",
        "    std[std[:] < 0.000001] = 1\n",
        "    Xtrain = (Xtrain - mean) / std\n",
        "    Xtest = (Xtest - mean) / std\n",
        "    # End Mean Var normalisation\n",
        "\n",
        "    # Classification.\n",
        "    if (isRegression == False):\n",
        "        numClasses = max(Ytrain_) - min(Ytrain_) + 1\n",
        "        numClasses = int(max(numClasses, max(Ytest_) - min(Ytest_) + 1))\n",
        "\n",
        "        lab = Ytrain_.astype('uint8')\n",
        "        lab = np.array(lab) - min(lab)\n",
        "\n",
        "        lab_ = np.zeros((Xtrain.shape[0], numClasses))\n",
        "        lab_[np.arange(Xtrain.shape[0]), lab] = 1\n",
        "        if (numClasses == 2):\n",
        "            Ytrain = np.reshape(lab, [-1, 1])\n",
        "        else:\n",
        "            Ytrain = lab_\n",
        "\n",
        "        lab = Ytest_.astype('uint8')\n",
        "        lab = np.array(lab) - min(lab)\n",
        "\n",
        "        lab_ = np.zeros((Xtest.shape[0], numClasses))\n",
        "        lab_[np.arange(Xtest.shape[0]), lab] = 1\n",
        "        if (numClasses == 2):\n",
        "            Ytest = np.reshape(lab, [-1, 1])\n",
        "        else:\n",
        "            Ytest = lab_\n",
        "\n",
        "    elif (isRegression == True):\n",
        "        # The number of classes is always 1, for regression.\n",
        "        numClasses = 1\n",
        "        Ytrain = Ytrain_\n",
        "        Ytest = Ytest_\n",
        "\n",
        "    trainBias = np.ones([Xtrain.shape[0], 1])\n",
        "    Xtrain = np.append(Xtrain, trainBias, axis=1)\n",
        "    testBias = np.ones([Xtest.shape[0], 1])\n",
        "    Xtest = np.append(Xtest, testBias, axis=1)\n",
        "\n",
        "    mean = np.append(mean, np.array([0]))\n",
        "    std = np.append(std, np.array([1]))\n",
        "\n",
        "    if (isRegression == False):\n",
        "        return dataDimension + 1, numClasses, Xtrain, Ytrain, Xtest, Ytest, mean, std\n",
        "    elif (isRegression == True):\n",
        "        return dataDimension + 1, numClasses, Xtrain, Ytrain.reshape((-1, 1)), Xtest, Ytest.reshape((-1, 1)), mean, std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYxSA8p-FFHx",
        "colab_type": "code",
        "outputId": "03feb7fa-c718-4a1a-cda9-0d2d8f213aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Loading and Pre-processing dataset for Bonsai\n",
        "\n",
        "#dataDir = \"sampled_dataset/\"\n",
        "dataDir = \"bot_iot_dataset/\"\n",
        "(dataDimension, numClasses, Xtrain, Ytrain, Xtest, Ytest, mean, std) = preProcessData(dataDir, isRegression=False)\n",
        "print(\"Feature Dimension: \", dataDimension)\n",
        "print(\"Num classes: \", numClasses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Dimension:  10\n",
            "Num classes:  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EdKH3bjEHzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigma = 1.0 #Sigmoid parameter for tanh\n",
        "depth = 3 #Depth of Bonsai Tree\n",
        "projectionDimension = 28 #Lower Dimensional space for Bonsai to work on\n",
        "\n",
        "#Regularizers for Bonsai Parameters\n",
        "regZ = 0.0001\n",
        "regW = 0.001\n",
        "regV = 0.001\n",
        "regT = 0.001\n",
        "\n",
        "#totalEpochs = 100\n",
        "totalEpochs = 20\n",
        "\n",
        "learningRate = 0.01\n",
        "\n",
        "outFile = None\n",
        "\n",
        "#Sparsity for Bonsai Parameters. x => 100*x % are non-zeros\n",
        "sparZ = 0.2\n",
        "sparW = 0.3\n",
        "sparV = 0.3\n",
        "sparT = 0.62\n",
        "\n",
        "batchSize = np.maximum(100, int(np.ceil(np.sqrt(Ytrain.shape[0]))))\n",
        "\n",
        "useMCHLoss = True #only for Multiclass cases True: Multiclass-Hing Loss, False: Cross Entropy. \n",
        "\n",
        "#Bonsai uses one classier for Binary, thus this condition\n",
        "if numClasses == 2:\n",
        "    numClasses = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP0sV4N7HyLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(\"float32\", [None, dataDimension])\n",
        "Y = tf.placeholder(\"float32\", [None, numClasses])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htOiT4IfIBPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "def createTimeStampDir(dataDir):\n",
        "    '''\n",
        "    Creates a Directory with timestamp as it's name\n",
        "    '''\n",
        "    if os.path.isdir(dataDir + '/TFBonsaiResults') is False:\n",
        "        try:\n",
        "            os.mkdir(dataDir + '/TFBonsaiResults')\n",
        "        except OSError:\n",
        "            print(\"Creation of the directory %s failed\" %\n",
        "                  dataDir + '/TFBonsaiResults')\n",
        "\n",
        "    currDir = 'TFBonsaiResults/' + datetime.datetime.now().strftime(\"%H_%M_%S_%d_%m_%y\")\n",
        "    if os.path.isdir(dataDir + '/' + currDir) is False:\n",
        "        try:\n",
        "            os.mkdir(dataDir + '/' + currDir)\n",
        "        except OSError:\n",
        "            print(\"Creation of the directory %s failed\" %\n",
        "                  dataDir + '/' + currDir)\n",
        "        else:\n",
        "            return (dataDir + '/' + currDir)\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMyN_TGxbNO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveMeanStdSeeDot(mean, std, seeDotDir):\n",
        "    '''\n",
        "    Function to save Mean and Std vectors\n",
        "    '''\n",
        "    if os.path.isdir(seeDotDir) is False:\n",
        "        try:\n",
        "            os.mkdir(seeDotDir)\n",
        "        except OSError:\n",
        "            print(\"Creation of the directory %s failed\" %\n",
        "                  seeDotDir)\n",
        "    np.savetxt(seeDotDir + '/Mean', mean, delimiter=\"\\t\")\n",
        "    np.savetxt(seeDotDir + '/Std', std, delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM43YJQlIK_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dumpCommand(list, currDir):\n",
        "    '''\n",
        "    Dumps the current command to a file for further use\n",
        "    '''\n",
        "    commandFile = open(currDir + '/command.txt', 'w')\n",
        "    command = \"python\"\n",
        "\n",
        "    command = command + \" \" + ' '.join(list)\n",
        "    commandFile.write(command)\n",
        "\n",
        "    commandFile.flush()\n",
        "    commandFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNA0gEbZHzZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "currDir = createTimeStampDir(dataDir)\n",
        "dumpCommand(sys.argv, currDir)\n",
        "saveMeanStdSeeDot(mean, std, currDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZXwRlwjInt4",
        "colab_type": "code",
        "outputId": "a1b90504-5688-470a-acba-09557e1a3233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "bonsaiObj = Bonsai(numClasses, dataDimension, projectionDimension, depth, sigma)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0716 15:41:21.574870 140428267288448 deprecation_wrapper.py:119] From /content/drive/My Drive/Dataset/EdgeML/tf/edgeml/graph/bonsai.py:70: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUy6c_jhIq5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bonsaiTrainer = BonsaiTrainer(bonsaiObj, regW, regT, regV, regZ, sparW, sparT, sparV, sparZ,\n",
        "                              learningRate, X, Y, useMCHLoss, outFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL4CklatIsox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXnz-5vmIxrN",
        "colab_type": "code",
        "outputId": "4db91474-89b3-48dc-94ce-bf682d049552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bonsaiTrainer.train(batchSize, totalEpochs, sess,\n",
        "                    Xtrain, Xtest, Ytrain, Ytest, dataDir, currDir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch Number: 0\n",
            "\n",
            "******************** Dense Training Phase Started ********************\n",
            "\n",
            "\n",
            "Classification Train Loss: 1.790632068055921\n",
            "Training accuracy (Classification): 0.8287201264823696\n",
            "Test accuracy 0.867157\n",
            "MarginLoss + RegLoss: 0.2991062 + 0.3078182 = 0.6069244\n",
            "\n",
            "\n",
            "Epoch Number: 1\n",
            "\n",
            "Classification Train Loss: 0.44351658567918084\n",
            "Training accuracy (Classification): 0.8890101759307152\n",
            "Test accuracy 0.896052\n",
            "MarginLoss + RegLoss: 0.24224678 + 0.11576569 = 0.35801247\n",
            "\n",
            "\n",
            "Epoch Number: 2\n",
            "\n",
            "Classification Train Loss: 0.3452580441283969\n",
            "Training accuracy (Classification): 0.9004327319892107\n",
            "Test accuracy 0.909227\n",
            "MarginLoss + RegLoss: 0.22963957 + 0.094196156 = 0.32383573\n",
            "\n",
            "\n",
            "Epoch Number: 3\n",
            "\n",
            "Classification Train Loss: 0.3230228577039938\n",
            "Training accuracy (Classification): 0.9041752780960725\n",
            "Test accuracy 0.910318\n",
            "MarginLoss + RegLoss: 0.22086951 + 0.08052658 = 0.3013961\n",
            "\n",
            "\n",
            "Epoch Number: 4\n",
            "\n",
            "Classification Train Loss: 0.29962147897587416\n",
            "Training accuracy (Classification): 0.906514369017255\n",
            "Test accuracy 0.910817\n",
            "MarginLoss + RegLoss: 0.21353313 + 0.07289528 = 0.28642842\n",
            "\n",
            "\n",
            "Epoch Number: 5\n",
            "\n",
            "Classification Train Loss: 0.2941242156434903\n",
            "Training accuracy (Classification): 0.9069432022824752\n",
            "Test accuracy 0.909681\n",
            "MarginLoss + RegLoss: 0.2184707 + 0.06735953 = 0.28583023\n",
            "\n",
            "\n",
            "Epoch Number: 6\n",
            "\n",
            "******************** IHT Phase Started ********************\n",
            "\n",
            "\n",
            "Classification Train Loss: 0.3439601572082106\n",
            "Training accuracy (Classification): 0.8945655173959985\n",
            "Test accuracy 0.893372\n",
            "MarginLoss + RegLoss: 0.2598612 + 0.101289354 = 0.36115056\n",
            "\n",
            "\n",
            "Epoch Number: 7\n",
            "\n",
            "Classification Train Loss: 0.33700337610413544\n",
            "Training accuracy (Classification): 0.9055787332817516\n",
            "Test accuracy 0.910318\n",
            "MarginLoss + RegLoss: 0.23253015 + 0.09288304 = 0.3254132\n",
            "\n",
            "\n",
            "Epoch Number: 8\n",
            "\n",
            "Classification Train Loss: 0.315152717309188\n",
            "Training accuracy (Classification): 0.9084246250907931\n",
            "Test accuracy 0.912998\n",
            "MarginLoss + RegLoss: 0.2201998 + 0.09468857 = 0.31488836\n",
            "\n",
            "\n",
            "Epoch Number: 9\n",
            "\n",
            "Classification Train Loss: 0.2983347185417614\n",
            "Training accuracy (Classification): 0.9106077749644761\n",
            "Test accuracy 0.913634\n",
            "MarginLoss + RegLoss: 0.1899148 + 0.0854625 = 0.2753773\n",
            "\n",
            "\n",
            "Epoch Number: 10\n",
            "\n",
            "Classification Train Loss: 0.2800216815244835\n",
            "Training accuracy (Classification): 0.9109586382334212\n",
            "Test accuracy 0.914316\n",
            "MarginLoss + RegLoss: 0.18126717 + 0.083687276 = 0.26495445\n",
            "\n",
            "\n",
            "Epoch Number: 11\n",
            "\n",
            "Classification Train Loss: 0.2728992857500515\n",
            "Training accuracy (Classification): 0.9111925471672969\n",
            "Test accuracy 0.91427\n",
            "MarginLoss + RegLoss: 0.17929798 + 0.084529065 = 0.26382706\n",
            "\n",
            "\n",
            "Epoch Number: 12\n",
            "\n",
            "Classification Train Loss: 0.27860400693870224\n",
            "Training accuracy (Classification): 0.908872949866067\n",
            "Test accuracy 0.913907\n",
            "MarginLoss + RegLoss: 0.17436497 + 0.088551 = 0.26291597\n",
            "\n",
            "\n",
            "Epoch Number: 13\n",
            "\n",
            "******************** Sparse Retraining Phase Started ********************\n",
            "\n",
            "\n",
            "Classification Train Loss: 0.317174317628409\n",
            "Training accuracy (Classification): 0.9106467585120581\n",
            "Test accuracy 0.919404\n",
            "MarginLoss + RegLoss: 0.19615453 + 0.12546211 = 0.32161665\n",
            "\n",
            "\n",
            "Epoch Number: 14\n",
            "\n",
            "Classification Train Loss: 0.29267322535799667\n",
            "Training accuracy (Classification): 0.9279365331198262\n",
            "Test accuracy 0.945618\n",
            "MarginLoss + RegLoss: 0.1520128 + 0.12551782 = 0.2775306\n",
            "\n",
            "\n",
            "Epoch Number: 15\n",
            "\n",
            "Classification Train Loss: 0.27404603665381405\n",
            "Training accuracy (Classification): 0.9389692413068451\n",
            "Test accuracy 0.940484\n",
            "MarginLoss + RegLoss: 0.13643771 + 0.12162184 = 0.25805956\n",
            "\n",
            "\n",
            "Epoch Number: 16\n",
            "\n",
            "Classification Train Loss: 0.25877337118165683\n",
            "Training accuracy (Classification): 0.9385988852091595\n",
            "Test accuracy 0.94112\n",
            "MarginLoss + RegLoss: 0.12947401 + 0.11137479 = 0.24084881\n",
            "\n",
            "\n",
            "Epoch Number: 17\n",
            "\n",
            "Classification Train Loss: 0.2533983786681057\n",
            "Training accuracy (Classification): 0.9394565520033372\n",
            "Test accuracy 0.940802\n",
            "MarginLoss + RegLoss: 0.13088639 + 0.11005041 = 0.2409368\n",
            "\n",
            "\n",
            "Epoch Number: 18\n",
            "\n",
            "Classification Train Loss: 0.25003118740510094\n",
            "Training accuracy (Classification): 0.9394370581196473\n",
            "Test accuracy 0.941347\n",
            "MarginLoss + RegLoss: 0.13100095 + 0.107813105 = 0.23881406\n",
            "\n",
            "\n",
            "Epoch Number: 19\n",
            "\n",
            "Classification Train Loss: 0.24829018834681638\n",
            "Training accuracy (Classification): 0.9389107651942599\n",
            "Test accuracy 0.941029\n",
            "MarginLoss + RegLoss: 0.1307908 + 0.10710024 = 0.23789105\n",
            "\n",
            "\n",
            "Non-Zero : 2772.0 Model Size: 20.890625 KB hasSparse: True\n",
            "\n",
            "For Classification, Maximum Test accuracy at compressed model size(including early stopping): 0.9456181 at Epoch: 15\n",
            "Final Test Accuracy: 0.9410295\n",
            "The Model Directory: bot_iot_dataset//TFBonsaiResults/15_41_21_16_07_19\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZetmElhwSnzK",
        "colab_type": "text"
      },
      "source": [
        "# Fast Cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGIjGQn_SsKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT license.\n",
        "\n",
        "import helpermethods\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "#Provide the GPU number to be used\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] =''\n",
        "\n",
        "#FastRNN and FastGRNN imports\n",
        "from edgeml.trainer.fastTrainer import FastTrainer\n",
        "from edgeml.graph.rnn import FastGRNNCell\n",
        "from edgeml.graph.rnn import FastRNNCell\n",
        "from edgeml.graph.rnn import UGRNNLRCell\n",
        "from edgeml.graph.rnn import GRULRCell\n",
        "from edgeml.graph.rnn import LSTMLRCell\n",
        "\n",
        "# Fixing seeds for reproducibility\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqHG5gyhTT7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preProcessData(dataDir):\n",
        "    '''\n",
        "    Function to pre-process input data\n",
        "    Expects a .npy file of form [lbl feats] for each datapoint,\n",
        "    feats is timesteps*inputDims, flattened across timestep dimension.\n",
        "    So input of 1st timestep followed by second and so on.\n",
        "    Outputs train and test set datapoints\n",
        "    dataDimension, numClasses are inferred directly\n",
        "    '''\n",
        "    \n",
        "    train = np.load(os.path.join(dataDir, 'train_all_classes.npy'))\n",
        "    test = np.load(os.path.join(dataDir, 'test_all_classes.npy'))\n",
        "    \n",
        "    '''\n",
        "    train = np.load(os.path.join(dataDir, 'train.npy'))\n",
        "    test = np.load(os.path.join(dataDir, 'test.npy'))\n",
        "    '''\n",
        "    dataDimension = int(train.shape[1]) - 1\n",
        "\n",
        "    Xtrain = train[:, 1:dataDimension + 1]\n",
        "    Ytrain_ = train[:, 0]\n",
        "    numClasses = max(Ytrain_) - min(Ytrain_) + 1\n",
        "\n",
        "    Xtest = test[:, 1:dataDimension + 1]\n",
        "    Ytest_ = test[:, 0]\n",
        "\n",
        "    numClasses = int(max(numClasses, max(Ytest_) - min(Ytest_) + 1))\n",
        "\n",
        "    # Mean Var Normalisation\n",
        "    mean = np.mean(Xtrain, 0)\n",
        "    std = np.std(Xtrain, 0)\n",
        "    std[std[:] < 0.000001] = 1\n",
        "    Xtrain = (Xtrain - mean) / std\n",
        "\n",
        "    Xtest = (Xtest - mean) / std\n",
        "    # End Mean Var normalisation\n",
        "\n",
        "    lab = Ytrain_.astype('uint8')\n",
        "    lab = np.array(lab) - min(lab)\n",
        "\n",
        "    lab_ = np.zeros((Xtrain.shape[0], numClasses))\n",
        "    lab_[np.arange(Xtrain.shape[0]), lab] = 1\n",
        "    Ytrain = lab_\n",
        "\n",
        "    lab = Ytest_.astype('uint8')\n",
        "    lab = np.array(lab) - min(lab)\n",
        "\n",
        "    lab_ = np.zeros((Xtest.shape[0], numClasses))\n",
        "    lab_[np.arange(Xtest.shape[0]), lab] = 1\n",
        "    Ytest = lab_\n",
        "\n",
        "    return dataDimension, numClasses, Xtrain, Ytrain, Xtest, Ytest, mean, std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw6HtAufVcMS",
        "colab_type": "code",
        "outputId": "c33bdfd2-d368-41e7-d144-32885c7c9451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Loading and Pre-processing dataset for FastCells\n",
        "#dataDir = \"usps10\"\n",
        "dataDir = \"sampled_dataset/\"\n",
        "#dataDir = \"bot_iot_dataset/\"\n",
        "\n",
        "#(dataDimension, numClasses, Xtrain, Ytrain, Xtest, Ytest, mean, std) = helpermethods.preProcessData(dataDir)\n",
        "(dataDimension, numClasses, Xtrain, Ytrain, Xtest, Ytest, mean, std) = preProcessData(dataDir)\n",
        "print(\"Feature Dimension: \", dataDimension)\n",
        "print(\"Num classes: \", numClasses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Dimension:  115\n",
            "Num classes:  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojxzQgoMVeqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cell = \"FastGRNN\" # Choose between FastGRNN, FastRNN, UGRNN, GRU and LSTM\n",
        "#cell = \"FastRNN\"\n",
        "#cell = \"GRU\"\n",
        "#cell = \"UGRNN\"\n",
        "cell = \"LSTM\"\n",
        "\n",
        "inputDims = 23 #29 58 for sampled_dataset\n",
        "\n",
        "\n",
        "#inputDims = 16 #features taken in by RNN in one timestep\n",
        "hiddenDims = 32 #hidden state of RNN\n",
        "\n",
        "totalEpochs = 20\n",
        "batchSize = 100\n",
        "\n",
        "learningRate = 0.01\n",
        "decayStep = 200\n",
        "decayRate = 0.1\n",
        "\n",
        "outFile = None #provide your file, if you need all the logging info in a file\n",
        "\n",
        "#low-rank parameterisation for weight matrices. None => Full Rank\n",
        "wRank = None \n",
        "uRank = None \n",
        "\n",
        "#Sparsity of the weight matrices. x => 100*x % are non-zeros\n",
        "sW = 1.0 \n",
        "sU = 1.0\n",
        "\n",
        "#Non-linearities for the RNN architecture. Can choose from \"tanh, sigmoid, relu, quantTanh, quantSigm\"\n",
        "update_non_linearity = \"tanh\"\n",
        "gate_non_linearity = \"sigmoid\"\n",
        "\n",
        "assert dataDimension % inputDims == 0, \"Infeasible per step input, Timesteps have to be integer\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbALg1FpViAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(\"float\", [None, int(dataDimension / inputDims), inputDims])\n",
        "Y = tf.placeholder(\"float\", [None, numClasses])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al5ozLfYTxF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "def createTimeStampDir(dataDir, cell):\n",
        "    '''\n",
        "    Creates a Directory with timestamp as it's name\n",
        "    '''\n",
        "    if os.path.isdir(os.path.join(dataDir, str(cell) + 'Results')) is False:\n",
        "        try:\n",
        "            os.mkdir(os.path.join(dataDir, str(cell) + 'Results'))\n",
        "        except OSError:\n",
        "            print(\"Creation of the directory %s failed\" %\n",
        "                  os.path.join(dataDir, str(cell) + 'Results'))\n",
        "\n",
        "    currDir = os.path.join(str(cell) + 'Results',\n",
        "        datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"))\n",
        "    if os.path.isdir(os.path.join(dataDir, currDir)) is False:\n",
        "        try:\n",
        "            os.mkdir(os.path.join(dataDir, currDir))\n",
        "        except OSError:\n",
        "            print(\"Creation of the directory %s failed\" %\n",
        "                  os.path.join(dataDir, currDir))\n",
        "        else:\n",
        "            return (os.path.join(dataDir, currDir))\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfdh1VR8WNkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#currDir = helpermethods.createTimeStampDir(dataDir, cell)\n",
        "currDir = createTimeStampDir(dataDir, cell)\n",
        "helpermethods.dumpCommand(sys.argv, currDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03PPWXfpWUs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create appropriate RNN cell object based on choice\n",
        "if cell == \"FastGRNN\":\n",
        "    FastCell = FastGRNNCell(hiddenDims, gate_non_linearity=gate_non_linearity,\n",
        "                            update_non_linearity=update_non_linearity,\n",
        "                            wRank=wRank, uRank=uRank)\n",
        "elif cell == \"FastRNN\":\n",
        "    FastCell = FastRNNCell(hiddenDims, update_non_linearity=update_non_linearity,\n",
        "                           wRank=wRank, uRank=uRank)\n",
        "elif cell == \"UGRNN\":\n",
        "    FastCell = UGRNNLRCell(hiddenDims, update_non_linearity=update_non_linearity,\n",
        "                           wRank=wRank, uRank=uRank)\n",
        "elif cell == \"GRU\":\n",
        "    FastCell = GRULRCell(hiddenDims, update_non_linearity=update_non_linearity,\n",
        "                         wRank=wRank, uRank=uRank)\n",
        "elif cell == \"LSTM\":\n",
        "    FastCell = LSTMLRCell(hiddenDims, update_non_linearity=update_non_linearity,\n",
        "                          wRank=wRank, uRank=uRank)\n",
        "else:\n",
        "    sys.exit('Exiting: No Such Cell as ' + cell)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DA4SWYvWVkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FastCellTrainer = FastTrainer(FastCell, X, Y, sW=sW, sU=sU, learningRate=learningRate, outFile=outFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc0vgk7hWY_d",
        "colab_type": "code",
        "outputId": "882e594a-1c5a-4558-d950-57b965f07726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajVZ_JJMWcT7",
        "colab_type": "code",
        "outputId": "fa46faaf-d562-4b6c-b8d4-6fee64b7cec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "FastCellTrainer.train(batchSize, totalEpochs, sess, Xtrain, Xtest, Ytrain, Ytest, decayStep, decayRate, dataDir, currDir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch Number: 0\n",
            "\n",
            "******************** Dense Training Phase Started ********************\n",
            "\n",
            "Train Loss: 0.5612154866709854 Train Accuracy: 0.7053024998517952\n",
            "Test Loss: 0.42163593 Test Accuracy: 0.7557108\n",
            "\n",
            "Epoch Number: 1\n",
            "Train Loss: 0.41326857456053145 Train Accuracy: 0.765506645043691\n",
            "Test Loss: 0.44322008 Test Accuracy: 0.7649141\n",
            "\n",
            "Epoch Number: 2\n",
            "Train Loss: 0.32954314603950036 Train Accuracy: 0.8112036141482266\n",
            "Test Loss: 0.30004606 Test Accuracy: 0.817963\n",
            "\n",
            "Epoch Number: 3\n",
            "Train Loss: 0.2842886553569274 Train Accuracy: 0.8322615618657584\n",
            "Test Loss: 0.27061695 Test Accuracy: 0.83981496\n",
            "\n",
            "Epoch Number: 4\n",
            "Train Loss: 0.25718898788245037 Train Accuracy: 0.8437214233658531\n",
            "Test Loss: 0.29274637 Test Accuracy: 0.8359449\n",
            "\n",
            "Epoch Number: 5\n",
            "Train Loss: 0.2545580920546946 Train Accuracy: 0.8458245606133432\n",
            "Test Loss: 0.24047999 Test Accuracy: 0.84023976\n",
            "\n",
            "Epoch Number: 6\n",
            "Train Loss: 0.2506020051060301 Train Accuracy: 0.8509994695885013\n",
            "Test Loss: 0.42968547 Test Accuracy: 0.7879932\n",
            "\n",
            "Epoch Number: 7\n",
            "Train Loss: 0.22872144829745245 Train Accuracy: 0.8586741070554714\n",
            "Test Loss: 0.21061455 Test Accuracy: 0.868888\n",
            "\n",
            "Epoch Number: 8\n",
            "Train Loss: 0.21324920779225803 Train Accuracy: 0.8629463042875734\n",
            "Test Loss: 0.19961233 Test Accuracy: 0.87285256\n",
            "\n",
            "Epoch Number: 9\n",
            "Train Loss: 0.23003233716343388 Train Accuracy: 0.858499734088628\n",
            "Test Loss: 0.21727073 Test Accuracy: 0.864782\n",
            "\n",
            "Epoch Number: 10\n",
            "Train Loss: 0.21612274017598893 Train Accuracy: 0.8643476884774487\n",
            "Test Loss: 0.22003108 Test Accuracy: 0.8557674\n",
            "\n",
            "Epoch Number: 11\n",
            "Train Loss: 0.2111065762211578 Train Accuracy: 0.8635321648433955\n",
            "Test Loss: 0.22027117 Test Accuracy: 0.85482347\n",
            "\n",
            "Epoch Number: 12\n",
            "Train Loss: 0.2134188923570845 Train Accuracy: 0.8636533762469436\n",
            "Test Loss: 0.22251225 Test Accuracy: 0.85312444\n",
            "\n",
            "Epoch Number: 13\n",
            "Train Loss: 0.22738701410666862 Train Accuracy: 0.8591759694947136\n",
            "Test Loss: 0.2187487 Test Accuracy: 0.86737776\n",
            "\n",
            "Epoch Number: 14\n",
            "Train Loss: 0.20491220079588168 Train Accuracy: 0.8659404558364792\n",
            "Test Loss: 0.2089977 Test Accuracy: 0.8572777\n",
            "\n",
            "Epoch Number: 15\n",
            "Train Loss: 0.20183790642203706 Train Accuracy: 0.867673578045585\n",
            "Test Loss: 0.2063759 Test Accuracy: 0.858316\n",
            "\n",
            "Epoch Number: 16\n",
            "Train Loss: 0.21566825006345305 Train Accuracy: 0.8617820291808157\n",
            "Test Loss: 0.20244032 Test Accuracy: 0.8710119\n",
            "\n",
            "Epoch Number: 17\n",
            "Train Loss: 0.20218654128939215 Train Accuracy: 0.8671334396709095\n",
            "Test Loss: 0.20408157 Test Accuracy: 0.87011516\n",
            "\n",
            "Epoch Number: 18\n",
            "Train Loss: 0.22397214421118147 Train Accuracy: 0.8602264748679267\n",
            "Test Loss: 0.2536696 Test Accuracy: 0.83636963\n",
            "\n",
            "Epoch Number: 19\n",
            "Train Loss: 0.19537598559952746 Train Accuracy: 0.8698426364648222\n",
            "Test Loss: 0.20431635 Test Accuracy: 0.8702096\n",
            "\n",
            "Maximum Test accuracy at compressed model size(including early stopping): 0.87285256 at Epoch: 9\n",
            "Final Test Accuracy: 0.8702096\n",
            "\n",
            "\n",
            "Non-Zeros: 7531 Model Size: 29.41796875 KB hasSparse: False\n",
            "\n",
            "The Model Directory: sampled_dataset/LSTMResults/2019-07-11T19-38-03\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}